# 🧹 Data Cleaning & Preprocessing Project

## 📌 Objective
This project focuses on cleaning and preprocessing a raw dataset to make it ready for data analysis or modeling. The dataset was chosen from Kaggle and contained common real-world issues such as missing values, duplicates, inconsistent formats, and incorrect data types.

## 🛠 Tools Used
- Python (Pandas)
- Jupyter Notebook / VS Code
- CSV format for input/output

## 🧪 Dataset
**Dataset Used**: *[Insert dataset name here, e.g., Mall Customer Segmentation Data]*  
Source: [Kaggle](https://www.kaggle.com/)  

## 🧼 Cleaning & Preprocessing Steps
- ✅ Identified and handled missing values using `isnull()` and `fillna()` / `dropna()`
- ✅ Removed duplicate records using `drop_duplicates()`
- ✅ Standardized categorical text values (e.g., gender, country)
- ✅ Converted date columns to consistent `datetime` format (e.g., dd-mm-yyyy)
- ✅ Renamed column headers to lowercase and removed spaces
- ✅ Fixed data types for numerical and datetime columns

## 📂 Files in this Repository
- `raw_dataset.csv` – Original uncleaned dataset (optional)
- `cleaned_dataset.csv` – Cleaned and preprocessed dataset
- `data_cleaning.py` – Python script for cleaning the dataset
- `summary_of_changes.txt` – Summary of all changes made
- `README.md` – This file

## 💡 Key Learnings
- Practical experience with data cleaning using Pandas
- Dealing with real-world data issues
- Understanding the importance of clean data in data science workflows

## ❓ Interview Questions You Can Practice
1. What are missing values and how do you handle them?
2. How do you treat duplicate records?
3. What’s the difference between `dropna()` and `fillna()`?
4. What is outlier treatment and why is it important?
5. How do you standardize data?
6. How do you handle inconsistent formats (e.g., date/time)?
7. What are common data cleaning challenges?
8. How do you check data quality?

---

